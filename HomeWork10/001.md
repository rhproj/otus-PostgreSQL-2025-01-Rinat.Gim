# Секционирование таблицы

Для выполнения задания исполюзую базу данных demo, демонстрационную базу данных авиаперевозок.

```sql
demo2=# select count(*) from bookings.bookings;    
 count     
---------  
2111110  
(1 row)  
  
demo2=# select extract(year from book_date) as year,  
count(*) as count from bookings.bookings  
group by year;  
year |  count     
-----+---------  
2016 |  852236  
2017 | 1258874  
(2 rows)  
  
demo2=# select * from bookings.bookings limit 5;  
book_ref |       book_date        | total_amount    
---------+------------------------+--------------  
000004   | 2016-08-13 15:40:00+03 |     55800.00  
00000F   | 2017-07-05 03:12:00+03 |    265700.00  
000010   | 2017-01-08 19:45:00+03 |     50900.00  
000012   | 2017-07-14 09:02:00+03 |     37900.00  
000026   | 2016-08-30 11:08:00+03 |     95600.00  
(5 rows)
```
Изучаю таблицу bookings,  предентента на секционирование.  Вижу что в год может выходить около миллиона записей, данные имеют ***временную природу***. Делаю вывод поле `book_date` - может быть неплохим выбором для поля секционирования.

**В реальных условиях, по хорошему** сначала ведется беседа с бизнесом, и изучается база в рабочем режиме некоторое время, с целью определить какие запросы выполняются чаще, на основании этого строить планы по секцианированию.  Берем во внимание, часто ли будут выполняться запросы не использующие фильтры по полю секционирования, ибо в таком случае секцианирование может быть не только бесполезно, но и вредно.

Предположим один из частых кейсов, встречающихся на практике - что наши запросы (аналитика и т.п) выполняются чаще в пределах одного промежутка времени, например года. Это позволит планировщику запросов PostgreSQL обращаться только к нужным секциям при выполнении запросов с фильтрацией по дате.


## Анализ исходной монолитной таблицы
Сначала проанализируем исходную монолитную таблицу и выполним несколько запросов для оценки производительности.

```sql
--анализ выполнения запроса на монотонной таблице по дате
demo2=# explain analyze  
select * from bookings.bookings     
where book_date = '2016-08-08';  

--------------------------------------------------------  
Gather  (cost=1000.00..25483.86 rows=5 width=21) (actual time=33.317..47.524 rows=3 loops=1)  
  Workers Planned: 2  
  Workers Launched: 2  
  ->  Parallel Seq Scan on bookings  (cost=0.00..24483.36 rows=2 width=21) (actual time=25.473..42.703 rows=1 loops=3)  
        Filter: (book_date = '2016-08-08 00:00:00+03'::timestamp with time zone)  
        Rows Removed by Filter: 703702  
Planning Time: 0.700 ms  
Execution Time: 47.704 ms  
(8 rows)  


demo2=# explain analyze  
select * from bookings.bookings     
where book_date = '2017-08-08';  

--------------------------------------------------------  
Gather  (cost=1000.00..25483.86 rows=5 width=21) (actual time=29.513..48.720 rows=6 loops=1)  
  Workers Planned: 2  
  Workers Launched: 2  
  ->  Parallel Seq Scan on bookings  (cost=0.00..24483.36 rows=2 width=21) (actual time=21.086..43.246 rows=2 loops=3)  
        Filter: (book_date = '2017-08-08 00:00:00+03'::timestamp with time zone)  
        Rows Removed by Filter: 703701  
Planning Time: 0.109 ms  
Execution Time: 48.747 ms  
(8 rows)  

demo2=#
--анализ выполнения запроса на монотонной таблице по диапазону

demo2-# explain analyze
select * from bookings.bookings  
where book_date between '2016-01-01' 
and '2016-12-31 23:59:59.999'; 

----------------------------------------------------------------
Seq Scan on bookings  (cost=0.00..45154.65 rows=853538 width=21) (act  
  Filter: ((book_date >= '2016-01-01 00:00:00+03'::timestamp with tim  
  Rows Removed by Filter: 1258874  
Planning Time: 0.220 ms  
Execution Time: 205.605 ms  
(5 rows)  


demo2=# explain analyze  
select * from bookings.bookings     
where book_date between '2017-01-01' and '2017-12-31 23:59:59.999';  

----------------------------------------------------------------
Seq Scan on bookings  (cost=0.00..45154.65 rows=1257155 width=21) (ac  
  Filter: ((book_date >= '2017-01-01 00:00:00+03'::timestamp with tim  
  Rows Removed by Filter: 852236  
Planning Time: 0.120 ms  
Execution Time: 219.555 ms  
(5 rows)
```
Далее планирую сравнить результаты с результатами партицианированных таблиц. Тут вижу, что  запросы выполняются относительно долго и требует полного сканирования таблицы.


Примерные запросы выполняемые бизнесом:
```sql
demo2=# select 
    extract(month from book_date) as month,
    count(*) as count,
    sum(total_amount) as total_revenue
from bookings.bookings
where book_date between '2016-01-01' and '2016-12-31 23:59:59.999'
group by extract(month from book_date)
order by month;

month | count  | total_revenue     
-------+--------+----------------  
    7 |  10878 |   859258900.00  
    8 | 168329 | 13366543300.00  
    9 | 165421 | 13138137200.00  
   10 | 170874 | 13545779100.00  
   11 | 165469 | 13133114900.00  
   12 | 171265 | 13588892200.00  
(6 rows)


-- Анализ запроса агрегации по месяцам за 2016 год
demo2=# explain analyze
select 
    extract(month from book_date) as month,
    count(*) as count,
    sum(total_amount) as total_revenue
from bookings.bookings
where book_date between '2016-01-01' and '2016-12-31 23:59:59.999'
group by extract(month from book_date)
order by month;

----------------------------------------------------------------  
GroupAggregate  (cost=154716.70..169355.42 rows=406889 width=72) (actual time=494.127..737.040 rows=6 loops=1)  
  Group Key: (EXTRACT(month FROM book_date))  
  ->  Sort  (cost=154716.70..156850.55 rows=853538 width=38) (actual time=491.044..609.963 rows=852236 loops=1)  
        Sort Key: (EXTRACT(month FROM book_date))  
        Sort Method: external merge  Disk: 18320kB  
        ->  Seq Scan on bookings  (cost=0.00..47288.49 rows=853538 width=38) (actual time=0.056..320.563 rows=852236 loops=1)  
              Filter: ((book_date >= '2016-01-01 00:00:00+03'::timestamp with time zone) AND (book_date <= '2016-12-31 23:59:59.999+03'::timestamp with ti  
              Rows Removed by Filter: 1258874  
Planning Time: 0.234 ms  
Execution Time: 739.519 ms  
(10 rows)  
```
Сравним эти результаты  после секцианировани

## Создание секционированной таблицы
Создаю секционированную таблицу `bookings_partitioned` 
```sql
demo2=# create table bookings_partitioned (  
    book_ref bpchar(6),  
    book_date timestamptz not null,  
    total_amount numeric(10,2) not null,  
    primary key (book_ref, book_date)  
) partition by range (book_date);  
CREATE TABLE  
```
Необходимо было также включать ключ-секционирования в головной таблице, у поля по которому буду разбивать данные, иначе не работало.

```sql
demo2=# create table bookings_2016 partition of bookings_partitioned  
for values from ('2016-01-01') to ('2017-01-01');  
CREATE TABLE  
demo2=# create table bookings_2017 partition of bookings_partitioned  
demo2-#     for values from ('2017-01-01') to ('2018-01-01');  
CREATE TABLE  
demo2=# create table bookings_2018 partition of bookings_partitioned  
demo2-#     for values from ('2018-01-01') to ('2019-01-01');  
CREATE TABLE  
```
Создал соответствующие секции для 2016, 2017, будущего 2018 года. В конце - указываю первый день следующего интервала. Т.о будут лежать 
данные в пределах указанного года.

```sql
demo2=# create table bookings_default partition of bookings_partitioned default;  
CREATE TABLE  
```
а также **default** партицию, в которую будут прилетать данные не соответствующие не одному из объявленных диапазонов.
На случай,  если вдруг не хватило партиции для какого-то условия, т.е дата выходит за рамки (например для будущих данных, для которых не успел создать партицию) - для этих целей создал партицию по умолчанию.
В будущем, default партицию,  в удобное время можно будет переменовать её в более подходящее, например под год партицианирования.

```sql
demo2=# \d+ bookings_partitioned;  
                                       Partitioned table "public.bookings_partitioned"  
   Column    |           Type           | Collation | Nullable | Default | Storage  | Compression | Stats target | Description    
--------------+--------------------------+-----------+----------+---------+----------+-------------+--------------+-------------  
book_ref     | character(6)             |           | not null |         | extended |             |              |    
book_date    | timestamp with time zone |           | not null |         | plain    |             |              |    
total_amount | numeric(10,2)            |           | not null |         | main     |             |              |    
Partition key: RANGE (book_date)  
Indexes:  
   "bookings_partitioned_pkey" PRIMARY KEY, btree (book_ref, book_date)  
Partitions: bookings_2016 FOR VALUES FROM ('2016-01-01 00:00:00+03') TO ('2017-01-01 00:00:00+03'),  
           bookings_2017 FOR VALUES FROM ('2017-01-01 00:00:00+03') TO ('2018-01-01 00:00:00+03'),  
           bookings_2018 FOR VALUES FROM ('2018-01-01 00:00:00+03') TO ('2019-01-01 00:00:00+03'),  
           bookings_default DEFAULT
```
Проверил наличие партиций у созданной таблицы.


### Миграция данных
После создания таблицы пустые:
```sql
demo2=# select count(*) from bookings_partitioned;  

count    
-------  
    0  
(1 row)  

demo2=# select count(*) from bookings_2017;  
count    
-------  
    0  
(1 row)  
```

Произвел перенос данных
```sql
demo2=# insert into bookings_partitioned  
select * from bookings.bookings;  
INSERT 0 2111110  

demo2=# select count(*) from bookings_partitioned;  
 count     
---------  
2111110  
(1 row)  
```

```sql
demo2=# select tableoid::regclass as partition_name,  
    count(*) as count  
from bookings_partitioned  
group by tableoid  
order by partition_name;  

partition_name |  count     
----------------+---------  
bookings_2016  |  852236  
bookings_2017  | 1258874  
(2 rows)  
```
Проверил распределения данных по секциям. Сравнив с тем что было в монолитной таблице (запрос вначале) вижу что колличества полностью соответствуют.


## Анализ секцианированной таблицы
Перед выполнением анализа убеждаюсь, что запрос по партициям включен
```sql
demo2=# show enable_partition_pruning;  
enable_partition_pruning    
--------------------------  
on  
(1 row)
```
Случай же выключения -   означал бы, что запрос выполняется с переходом от одной секции к другой, что только  ухудшает результат с секционированием.
 

Выполняю те же запросы к секционированной таблице что делал к монолитной и сравниваю производительность:
```sql
demo2=# explain analyze     
select * from bookings_partitioned        
where book_date = '2016-08-08';  

----------------------------------------------
Gather  (cost=1000.00..10868.23 rows=5 width=21) (actual time=8.382..29.494 rows=3 loops=1)  
  Workers Planned: 2  
  Workers Launched: 2  
  ->  Parallel Seq Scan on bookings_2016 "  "  (cost=0.00..9867.73 rows=2 width=21) (actual time=11.467..21.0  
        Filter: (book_date = '2016-08-08 00:00:00+03'::timestamp with time zone)  
        Rows Removed by Filter: 284078  
Planning Time: 0.191 ms  
Execution Time: 29.523 ms  
(8 rows)


demo2=#  explain analyze     
select * from bookings_partitioned        
where book_date = '2017-08-08';  

---------------------------------------------  
Gather  (cost=1000.00..15576.14 rows=5 width=21) (actual time=25.755..38.822 rows=6 loops=1)  
  Workers Planned: 2  
  Workers Launched: 2  
  ->  Parallel Seq Scan on bookings_2017 "  "  (cost=0.00..14575.64 rows=2 width=21) (actual time=17.826..29.743 rows=2 loops=3)  
        Filter: (book_date = '2017-08-08 00:00:00+03'::timestamp with time zone)  
        Rows Removed by Filter: 419623  
Planning Time: 0.220 ms  
Execution Time: 38.851 ms  
(8 rows)
```
Ключевое, я вижу что теперь скан выполняется по партиции "**Parallel Seq Scan on bookings_2016** " и "**bookings_2017**" в зависимости от того ищу я данные с  book_date  **2016** или **2017**

Условная стоимость стала меньше  **cost=0.00..9 867.73**  ( было =0.00..**24 483.36**)
И в каждом случаи фильтрация происходит в рамках секции
Rows Removed by Filter: **284 078**  
Rows Removed by Filter:  **419 623** 
			    против **703 702**  на монолитной таблице.

Время выполнения в целом тоже стало меньше **29.523 ms**  потив **47.704 ms**


```sql
demo2=# explain analyze     
select * from bookings_partitioned        
where book_date between '2016-01-01' and '2016-12-31 23:59:59.999';  

---------------------------------------------------------   
Seq Scan on bookings_2016 "  "  (cost=0.00..18212.54 rows=852066 width=21) (actual time=0.087..97.645 rows=85  
  Filter: ((book_date >= '2016-01-01 00:00:00+03'::timestamp with time zone) AND (book_date <= '2016-12-31 23  
Planning Time: 0.285 ms  
Execution Time: 126.444 ms  
(4 rows)
```
```sql
demo2=# explain analyze     
select * from bookings_partitioned        
where book_date between '2017-01-01' and '2017-12-31 23:59:59.999';  

---------------------------------------------------------  
Seq Scan on bookings_2017 "  "  (cost=0.00..26902.11 rows=1258622 width=21) (actual time=0.069..111.538 rows=1258874 loops=1)  
  Filter: ((book_date >= '2017-01-01 00:00:00+03'::timestamp with time zone) AND (book_date <= '2017-12-31 23:59:59.999+03'::timestamp with t  
Planning Time: 0.232 ms  
Execution Time: 143.753 ms  
(4 rows)
```
Аналогичная история по поиску в диапахонах, в целом время выполнения в двое меньше
Seq Scan on bookings_2016 **Execution Time: 126.444 ms**   ( на молитной **205.605 ms** )
Seq Scan on bookings_2017 **Execution Time: 143.753 ms**    ( на молитной **219.555 ms** )


```sql
demo2=#  select    
    extract(month from book_date) as month,  
    count(*) as count,  
    sum(total_amount) as total_revenue  
from bookings_partitioned  
where book_date between '2016-01-01' and '2016-12-31 23:59:59.999'  
group by extract(month from book_date)  
order by month;  

month | count  | total_revenue     
-------+--------+----------------  
    7 |  10878 |   859258900.00  
    8 | 168329 | 13366543300.00  
    9 | 165421 | 13138137200.00  
   10 | 170874 | 13545779100.00  
   11 | 165469 | 13133114900.00  
   12 | 171265 | 13588892200.00  
(6 rows)
```
Убеждаюсь что запрос к секцианированной таблице, например агригации по месецам выдал точно такие же данные как и монолитная таблица, и ничего не утеряно.

```sql
demo2=# explain analyze  
select    
    extract(month from book_date) as month,  
     count(*) as count,  
    sum(total_amount) as total_revenue  
 from bookings_partitioned  
 where book_date between '2016-01-01' and '2016-12-31 23:59:59.999'  
 group by extract(month from book_date)  
 order by month;  

----------------------------------------------------------------------------------  
Finalize GroupAggregate  (cost=17091.56..17145.23 rows=200 width=72) (actual time=147.160..149.739 rows=6 loops=1)  
  Group Key: (EXTRACT(month FROM bookings_partitioned.book_date))  
  ->  Gather Merge  (cost=17091.56..17138.23 rows=400 width=72) (actual time=147.150..149.721 rows=18 loops=1)  
        Workers Planned: 2  
        Workers Launched: 2  
        ->  Sort  (cost=16091.54..16092.04 rows=200 width=72) (actual time=144.892..144.893 rows=6 loops=3)  
              Sort Key: (EXTRACT(month FROM bookings_partitioned.book_date))  
              Sort Method: quicksort  Memory: 25kB  
              Worker 0:  Sort Method: quicksort  Memory: 25kB  
              Worker 1:  Sort Method: quicksort  Memory: 25kB  
              ->  Partial HashAggregate  (cost=16080.89..16083.89 rows=200 width=72) (actual time=144.868..144.871 rows=6 loops=3)  
                    Group Key: EXTRACT(month FROM bookings_partitioned.book_date)  
                    Batches: 1  Memory Usage: 40kB  
```
Анализ производительности этого запроса серьезно разнится в лучшую сторону с анализом на монолитной таблице.

| Аспект                | До секционирования                     | После секционирования                              | Изменение                |
|-----------------------|---------------------------------------|--------------------------------------------------|--------------------------|
| Тип агрегации         | GroupAggregate                        | Finalize GroupAggregate с Partial HashAggregate  | Улучшение                |
| Метод сканирования    | Seq Scan на всей таблице              | Параллельное сканирование только нужной секции   | Улучшение                |
| Метод сортировки      | External merge на диске (18320kB)     | Quicksort в памяти (25kB)                        | Значительное улучшение   |
| Параллелизм          | Нет                                   | 2 рабочих процесса                               | Улучшение                |
| Время выполнения     | 739.519 мс                           | ~150 мс (по времени последнего этапа)           | ~80% улучшение           |


## Дополнительные тесты
Так же я провел серию тестов с работой с партицианированной таблицей, чтобы убедиться что данные попадают в нужную партицию, и все необходимые для работы запросы отрабатывают

```sql
-- тестирование вставки новой записи за 2016 год
insert into bookings_partitioned (book_ref, book_date, total_amount)
values ('test01', '2016-06-15 12:00:00', 50000.00);

-- проверка, что запись попала в нужную секцию
select * from bookings_2016 where book_ref = 'test01';

-- тестирование вставки новой записи за 2017 год
insert into bookings_partitioned (book_ref, book_date, total_amount)
values ('test02', '2017-06-15 12:00:00', 60000.00);

-- проверка, что запись попала в нужную секцию
select * from bookings_2017 where book_ref = 'test02';

-- тестирование обновления записи
update bookings_partitioned
set total_amount = 55000.00
where book_ref = 'test01';

-- проверка обновления
select * from bookings_2016 where book_ref = 'test01';

-- тестирование удаления записи
delete from bookings_partitioned
where book_ref = 'test02';

-- проверка удаления
select * from bookings_2017 where book_ref = 'test02';
```

```sql
-- тестирование вставки новой записи за текущий год (должна попасть в default секцию)
demo2=#  insert into bookings_partitioned (book_ref, book_date, total_amount)
values ('test03', current_timestamp, 70000.00);
INSERT 0 1 


-- проверка, что запись попала в default секцию
demo2=# select * from bookings_default where book_ref = 'test03';  
book_ref |          book_date           | total_amount    
----------+------------------------------+--------------  
test03   | 2025-04-06 14:36:24.53021+03 |     70000.00  
(1 row)
```
Действительно, всё отработало как нужно.


## Итоги

Подытожив, можно смело утверждать что на больших данных партицианирование положительно сказывается на работе с таблицей
 - При выполнении запросов к секционированной таблице выбираются только нужные секцию (partition pruning), что  ускоряет выполнение запросов:
- Секционирование позволяет более эффективно управлять данными, например, архивировать или удалять старые данные путем отсоединения целых секций.
 - Операции обслуживания (VACUUM, ANALYZE) могут выполняться на отдельных секциях, что снижает нагрузку на систему.
- Операции вставки, обновления и удаления работают корректно, данные автоматически распределяются по соответствующим секциям.
- Механизм DEFAULT секции обеспечивает корректную обработку данных за годы, для которых еще не созданы отдельные секции.

Учитываем ещё следующий  факт:
что наиболее востребованными оказываются недавние записи, за полседний год, записи 3-ёх летней давновсти - нужны реже и можно постепенно разделять такие перенося на медленные носители, например создавая TableSpace в на таком носителе.

